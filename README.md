# ğŸ¤– AI Resume Analyzer & LinkedIn Scraper

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.48.1-red.svg)](https://streamlit.io/)
[![Groq](https://img.shields.io/badge/Groq-LLaMA3-green.svg)](https://console.groq.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An intelligent web application that combines **AI-powered resume analysis** with **automated LinkedIn job scraping**. This comprehensive tool helps job seekers gain deep insights into their resumes while simultaneously discovering relevant job opportunities.

## ğŸš€ Live Demo

**Try the live application:** [ResumeRadarAI on Streamlit](https://resumeradarai.streamlit.app/)

## âœ¨ Features

### ğŸ“„ **Resume Analysis**
- **ğŸ“Š Comprehensive Analysis** - Strengths, weaknesses, and improvement suggestions
- **ğŸ“‹ Summary Generation** - Quick overview of your resume
- **ğŸ’¡ Job Title Recommendations** - Personalized job suggestions
- **ğŸ¯ AI-Powered Insights** - Using Groq's LLaMA 3 model

### ğŸ” **LinkedIn Scraper**
- **ğŸ¤– Automated Job Search** - No manual browsing needed
- **ğŸ“Š Rich Data Extraction** - Company, title, location, description
- **ğŸ”— Direct Application Links** - Ready to apply
- **ğŸŒ Location-Based Search** - Find jobs in your area

## ğŸ› ï¸ Technology Stack

### **Frontend & Web Framework**
- **Streamlit** - Modern web application framework
- **Streamlit Option Menu** - Enhanced navigation components
- **Streamlit Extras** - Additional UI components

### **AI & Machine Learning**
- **LangChain** - LLM-powered application framework
- **Groq API** - Ultra-fast inference API (LLaMA 3 8B model)
- **HuggingFace Transformers** - State-of-the-art NLP models
- **Sentence Transformers** - Advanced text embedding
- **FAISS** - High-performance vector similarity search

### **Data Processing & Analysis**
- **Pandas** - Data manipulation and analysis
- **NumPy** - Scientific computing
- **PyPDF2** - PDF text extraction
- **RAG Pipeline** - Retrieval-Augmented Generation

### **Web Automation & Scraping**
- **Selenium WebDriver** - Automated browser control
- **Chrome WebDriver** - Browser automation
- **WebDriver Manager** - Automatic driver management

## ğŸš€ Quick Start

### **Option 1: One-Click Setup (Windows)**
```bash
# 1. Clone the repository
git clone https://github.com/yourusername/AI-Resume-Analyzer.git
cd AI-Resume-Analyzer

# 2. Double-click setup.bat to install dependencies
# 3. Double-click start.bat to run the app
# 4. Open http://localhost:8501 in your browser
```

### **Option 2: Manual Setup**
```bash
# 1. Clone the repository
git clone https://github.com/yourusername/AI-Resume-Analyzer.git
cd AI-Resume-Analyzer

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run the application
python -m streamlit run app.py

# 4. Open http://localhost:8501 in your browser
```

### **Option 3: Status Check**
```bash
# Check if everything is installed correctly
python check_status.py
```

## ğŸ“‹ Prerequisites

- **Python 3.8+** installed on your system
- **Groq API Key** (free from [https://console.groq.com/](https://console.groq.com/))
- **PDF Resume** for analysis
- **Internet connection** for LinkedIn scraping

## ğŸ”‘ Getting Groq API Key

1. Visit [https://console.groq.com/](https://console.groq.com/)
2. Sign up for a free account
3. Create an API key in the dashboard
4. Use the key in the application

## ï¿½ï¿½ Project Structure

```
AI-Resume-Analyzer/
â”œâ”€â”€ ğŸš€ app.py                 # Main application (690 lines)
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ âš¡ start.bat             # One-click run script (Windows)
â”œâ”€â”€ ğŸ› ï¸ setup.bat            # One-click install script (Windows)
â”œâ”€â”€ ğŸ” check_status.py       # Dependency checker
â”œâ”€â”€ ğŸ“„ demo_resume.txt       # Sample resume for testing
â”œâ”€â”€ ğŸ“– README.md             # This file
â””â”€â”€ ğŸš« .gitignore            # Git ignore rules
```

## ğŸ¯ How It Works

### **Resume Analysis Pipeline**
```
PDF Resume â†’ Text Extraction â†’ AI Analysis â†’ Insights
```

1. **Upload PDF Resume** â†’ User uploads their resume
2. **Text Extraction** â†’ PyPDF2 extracts text from PDF
3. **Text Chunking** â†’ LangChain splits text into manageable chunks
4. **AI Processing** â†’ Groq LLM analyzes the content
5. **Results** â†’ Returns comprehensive analysis

### **LinkedIn Scraping Pipeline**
```
Job Search â†’ Web Scraping â†’ Data Processing â†’ Results
```

1. **User Input** â†’ Job title, location, number of jobs
2. **URL Building** â†’ Creates LinkedIn search URL
3. **Web Scraping** â†’ Selenium automates browser to scrape data
4. **Data Extraction** â†’ Gets company names, job titles, descriptions
5. **Results Display** â†’ Shows formatted job listings

## ğŸ”§ Configuration

### **Environment Variables**
Create a `.env` file in the project root:
```env
GROQ_API_KEY=your_groq_api_key_here
HUGGINGFACEHUB_API_TOKEN=your_huggingface_token_here
```

### **Customization**
- Modify `app.py` to change AI prompts
- Update `requirements.txt` for different dependencies
- Customize UI in Streamlit components

## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit a Pull Request.

### **Development Setup**
```bash
# 1. Fork the repository
# 2. Clone your fork
git clone https://github.com/yourusername/AI-Resume-Analyzer.git

# 3. Create a feature branch
git checkout -b feature/amazing-feature

# 4. Make your changes
# 5. Commit and push
git commit -m "Add amazing feature"
git push origin feature/amazing-feature

# 6. Open a Pull Request
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Groq** for providing ultra-fast LLM inference
- **Streamlit** for the amazing web framework
- **LangChain** for LLM orchestration tools
- **HuggingFace** for transformer models
- **Selenium** for web automation capabilities

## ğŸ“ Support

If you encounter any issues or have questions:

1. **Check the documentation** in this README
2. **Run the status checker**: `python check_status.py`
3. **Open an issue** on GitHub
4. **Contact the maintainers**

## ğŸš€ Deployment

### **Streamlit Cloud**
1. Push your code to GitHub
2. Connect your repository to [Streamlit Cloud](https://streamlit.io/cloud)
3. Deploy automatically

### **Local Deployment**
```bash
# Install dependencies
pip install -r requirements.txt

# Run with custom port
streamlit run app.py --server.port 8080
```

---

**â­ Star this repository if you find it helpful!**

**ğŸ”— Share with your network to help other job seekers!**
